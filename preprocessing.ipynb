{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ehfFcXasjdR7","executionInfo":{"status":"ok","timestamp":1653226397182,"user_tz":-120,"elapsed":5091,"user":{"displayName":"Екатерина Батуева","userId":"01337052685936802745"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"72925dec-85eb-4622-e5ca-2eb42cb4d3de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyreadr in /usr/local/lib/python3.7/dist-packages (0.4.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyreadr) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadr) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadr) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadr) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyreadr) (1.15.0)\n"]}],"source":["#!pip install pyreadr\n","#!pip install imbalanced-learn\n","import pyreadr\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n","from sklearn.ensemble import IsolationForest\n","\n","import imblearn\n","from imblearn.over_sampling import SMOTE\n","from collections import Counter"]},{"cell_type":"code","source":["def encode_variables(df):\n","  '''Using one-hot encoding to divide categorical features to binary\n","  splitting multi-categorical values over several columns.'''\n","  \n","  #rename labels into english\n","  df.fd.replace('ПФО', 'PFO', inplace=True)\n","\n","  #Generate column and lables with one hot encoding\n","  df = pd.get_dummies(df, columns = ['fd'], prefix='fd') \n","\n","  return df"],"metadata":{"id":"PsjzygnBvOKW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def handle_missing_values(df, row_thresh=None, col_thresh=None):\n","  ''' Removes rows and columns from given dataframe object with a number of \n","  missing values above the given threshholds. Removes rows with any nan if threshold arguemnt is not given'''\n","\n","  #Remove rows with more than row_thresh NaN Values  \n","  if (row_thresh != None):  \n","    thresh_count_row = int((1-row_thresh) * df.shape[1] + 1)\n","    df = df.dropna(axis=0, thresh=thresh_count_row).copy()\n","\n","  #Remove columns with more than col_thresh NaN Values    \n","  if (col_thresh != None):\n","    thresh_count_col = int((1-col_thresh) * df.shape[0] + 1)\n","    df = df.dropna(axis=1, thresh=thresh_count_col).copy()\n","\n","  #Remove rows with any missing values\n","  if (row_thresh == None) and (col_thresh == None):\n","    df = df.dropna()\n","\n","  return df"],"metadata":{"id":"PoE_FVaEOf81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_outliers(df, contamination=0.1):\n","  ''' Gives indexes of outliers detected by sklearn.IsolationForest() in given dataset. '''\n","\n","  #identifying outliers\n","  clf = IsolationForest(contamination=contamination).fit(df)\n","  outliers = clf.predict(df)\n","\n","  #returns the position of outliers in the dataframe\n","  outlier_idx = outliers != -1\n","\n","  return outlier_idx"],"metadata":{"id":"RqhETDjABSA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_data(df):\n","  '''Removing specified columns that are considered irrelevant for the a-priori\n","  classification task and removes filters that do not match pre-defined values. '''\n","\n","  #Filtering rows based on variable values \n","  df = df[df['platform'] == 'Sber'].reset_index(drop=True)\n","  df = df[df['pmeth'] == 'EA'].reset_index(drop=True)\n","  df = df[df['law'] == '44-FZ'].reset_index(drop=True)\n","  df = df[df['nAppr1sber'] >= 2].reset_index(drop=True)\n","\n","  #Removing irrelevant columns for classification task\n","  remove_cols = ['row', 'aucID', 'nAppr1gos','law', 'nRej1gos', 'pathol', 'innORG', 'innBUY', 'icpReducPct', 'platform', 'pmeth', 'icpOR', 'aucYearOR', 'firstBidDur', 'bv1hour', 'contractSec']\n","  df.drop(remove_cols, inplace=True, axis=1)\n","\n","  # filtering only prior features\n","  df_prior = df.copy()\n","  remove_post = ['wpp', 'nAppr2', 'nPart', 'single', 'invalid', 'broke'] # remove posterior features\n","  df_prior.drop(remove_post, inplace=True, axis=1)\n","  filtered_shape = df_prior.shape\n","\n","  return df_prior"],"metadata":{"id":"TQxErSLhu4ml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scale_variables(df):\n","  ''' Scaling non-binary numerical variables to scale of 0 to 1. '''\n","\n","  scaling_list = [\"icpKZ\", \"nAppr1sber\", \"claimSec\", \"n1hour\"]\n","\n","  scaler = RobustScaler()\n","  robust_df = scaler.fit_transform(df)\n","  robust_df = pd.DataFrame(robust_df, index=df.index, columns=df.columns)\n","\n","  norm_scaler = MinMaxScaler()\n","  normalized = norm_scaler.fit_transform(robust_df)\n","  df = pd.DataFrame(normalized, index=df.index, columns=df.columns)\n","\n","\n","  #normalization by min/max\n","  #for column in scaling_list:\n","  #df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())   \n","\n","  #if (scale_type == 'stan'):\n","  #  scaler = StandardScaler()\n","  #  standardized = scaler.fit_transform(df.values)\n","  #  df = pd.DataFrame(standardized, index=df.index, columns=df.columns)\n","\n","  #for column in scaling_list:\n","  #  df[column] = np.log(df[column])   \n","\n","  return df"],"metadata":{"id":"xATvlfevNH5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def oversample(X, y):\n","  '''Performes oversampling/upsampling of training data and corresponding labels \n","  using imblearn.SMOTE().'''\n","  \n","  counter = Counter(y)\n","  print(counter)\n","\n","  # transform the dataset\n","  oversample = SMOTE()\n","  X, y = oversample.fit_resample(X, y)\n","  \n","  # summarize the new class distribution\n","  counter = Counter(y)\n","  print(counter)\n","  \n","  return X, y"],"metadata":{"id":"1ga4-ATxkBjW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_splits(df, labelcol):\n","  ''' Creates train and test splits with labels from dataframe using sklearn \n","  built-in-function. Takes dataframe and name of column with labels.'''\n","\n","  x = df.loc[:, df.columns != labelcol]\n","  y = df.collusion\n","  \n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=6)\n","\n","  print('Shape of x and y before split', x.shape, y.shape)\n","  print('Shape of x_train and x_test after split', x_train.shape, x_test.shape)\n","  print('Train set contains {0} pct ratio of collusion labels'.format((y_train.sum()/y_train.shape[0])*100))\n","  print('Test set contains {0} pct ratio of collusion labels\\n'.format((y_test.sum()*100/y_test.shape[0])))\n","\n","  return x_train, x_test, y_train, y_test"],"metadata":{"id":"G09qHzeV_XI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Connnect to google drive \n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5OV6jHuQtX_c","executionInfo":{"status":"ok","timestamp":1653226046462,"user_tz":-120,"elapsed":15847,"user":{"displayName":"Екатерина Батуева","userId":"01337052685936802745"}},"outputId":"9a185c63-6827-4e7c-fbd9-22e95b33fda8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["### Uncomment to run"],"metadata":{"id":"93uA8vG5gFiz"}},{"cell_type":"code","source":["# #loading hiv and tubercolosis data\n","# data_hiv = pyreadr.read_r('/content/gdrive/MyDrive/ML-exam/dataprocessing/dataHIV.Rdata')['dfHIV']\n","# data_tb = pyreadr.read_r('/content/gdrive/MyDrive/ML-exam/dataprocessing/dataTB.RData')['dfTB']\n","# data_combined = pd.concat([data_hiv, data_tb], ignore_index=True)\n","# df_comb = data_combined.copy()\n","\n","# df_comb = df_comb.drop('aucDateOR', axis=1)\n","\n","# #imputing nan value for ClaimSec\n","# df_comb.loc[df_comb[df_comb.aucID == \"0306500000117000001\"].index,\"claimSec\"] = 1611.80\n","# df_comb.loc[df_comb[df_comb.aucID == \"0356200006718000097\"].index,\"claimSec\"] = 424.1\n","\n","# #imputing nan value for bvSameBO\n","# df_comb.loc[df_comb[df_comb.aucID == \"0888500000219000457\"].index,\"bvSameBO\"] = 1"],"metadata":{"id":"fr-7N4vzCs6Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_comb = encode_variables(df_comb)\n","# print('Before filtering', df_comb.shape)\n","\n","#df_comb = filter_data(df_comb)\n","#df_comb = scale_variables(df_comb)\n","\n","#print('Before handling missing values', df_comb.shape)\n","#df_comb_clean = handle_missing_values(df_comb.copy(), 0.25, 0.9)\n","\n","#print('After preprocessing', df_comb.shape)\n","\n","#split on cleaned data\n","#x_train, x_test, y_train, y_test = create_splits(df_comb_clean, 'collusion')\n","\n","\n","#split on data with removed nans\n","#df_comb_removed = handle_missing_values(df_comb)\n","#print('After handling missing values', df_comb_removed.shape)\n","\n","#df_comb_removed = df_comb.dropna().copy()\n","#x_train_r, x_test_r, y_train_r, y_test_r = create_splits(df_comb_removed, 'collusion')\n","\n","#mask = remove_outliers(x_train_r, 0.15)\n","#x_train_r, y_train_r = x_train_r.iloc[mask, :], y_train_r.iloc[mask] \n","#print('After handling outliers', x_train_r.shape)\n","\n","#x_train_r, y_train_r = oversample(x_train_r, y_train_r)"],"metadata":{"id":"uQmzUV82gJcw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653226099589,"user_tz":-120,"elapsed":206,"user":{"displayName":"Екатерина Батуева","userId":"01337052685936802745"}},"outputId":"4eb3eb9e-adb5-471b-dfb8-72d12db8bb3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Before filtering (187287, 45)\n"]}]},{"cell_type":"code","source":["\n","df_comb = filter_data(df_comb)\n","df_comb = scale_variables(df_comb)"],"metadata":{"id":"K1mrHFe69FB8","executionInfo":{"status":"ok","timestamp":1653226111555,"user_tz":-120,"elapsed":693,"user":{"displayName":"Екатерина Батуева","userId":"01337052685936802745"}},"outputId":"a2c2cc71-48a2-48df-f92d-08b4db76e425","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:1565: RuntimeWarning: invalid value encountered in subtract\n","  X -= self.center_\n"]}]},{"cell_type":"code","source":["data_hiv = pyreadr.read_r('/content/gdrive/MyDrive/ML-exam/dataprocessing/dataHIV.Rdata')['dfHIV']\n","data_tb = pyreadr.read_r('/content/gdrive/MyDrive/ML-exam/dataprocessing/dataTB.RData')['dfTB']"],"metadata":{"id":"UxkwLS1O9H1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_tb.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY21WA6h-Z4m","executionInfo":{"status":"ok","timestamp":1653227086997,"user_tz":-120,"elapsed":250,"user":{"displayName":"Екатерина Батуева","userId":"01337052685936802745"}},"outputId":"590d3536-36c1-48ce-91b8-01d7fd1da311"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(148720, 39)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[""],"metadata":{"id":"1RJS0PMgA2FU"},"execution_count":null,"outputs":[]}]}